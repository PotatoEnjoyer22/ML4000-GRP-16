{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e3fdc16",
   "metadata": {
    "papermill": {
     "duration": 0.004348,
     "end_time": "2022-07-20T12:57:40.462629",
     "exception": false,
     "start_time": "2022-07-20T12:57:40.458281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Group 16\n",
    "\n",
    "Credit cards play an important role in modern life, offering both convenience and flexibility when making everyday purchases. Whether one is at a restaurant or making online purchases, the actual or digital credit cards can get it done. While they allow consumers to spend without carrying cash and even adopt a “buy now pay later” policy, the responsibility of managing the risk falls on card issuers. One of the biggest questions for lenders, especially commercial banks, is determining whether a customer is likely to repay what they borrow.\r\n",
    "\r\n",
    "To accurately predict credit default is essential for financial institutions, as this facilitates their ability to make more informed lending decisions and manage risk more effectively. In this project, we will focus on applying machine learning techniques to develop and optimize various models that can predict credit default using the large and complex dataset provided by American Express. The dataset includes anonymized customer profiles along with behavioral data collected over time, which creates both an opportunity and a challenge for model development.\r\n",
    "\r\n",
    "While the goal of our project is simply to predict if a customer will default in the future, this presents the opportunity to build a model that can improve on existing solutions, helping lenders make better decisions and offering a smoother experience for customers seeking credit.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7275d4-d4ee-4150-b2fb-2f377a579c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking CUDA toolkit (for V100 GPU support):\n",
      "✅ CUDA toolkit is installed.\n",
      "Build cuda_12.6.r12.6/compiler.35059454_0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nChecking CUDA toolkit (for V100 GPU support):\")\n",
    "import subprocess\n",
    "try:\n",
    "    output = subprocess.check_output([\"nvcc\", \"--version\"]).decode()\n",
    "    print(\"✅ CUDA toolkit is installed.\")\n",
    "    print(output.split('\\n')[-2])  # Print CUDA version line\n",
    "except Exception as e:\n",
    "    print(\"❌ CUDA toolkit (nvcc) is NOT installed or not in PATH.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d38e3a-e058-434c-a8cb-68311db0db1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Python libraries:\n",
      "✅ gc is installed.\n",
      "✅ warnings is installed.\n",
      "✅ scipy is installed.\n",
      "✅ numpy is installed.\n",
      "✅ pandas is installed.\n",
      "✅ tqdm is installed.\n",
      "✅ itertools is installed.\n",
      "✅ os is installed.\n",
      "✅ random is installed.\n",
      "✅ joblib is installed.\n",
      "✅ lightgbm is installed.\n",
      "✅ sklearn is installed.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "required_libraries = [\n",
    "    \"gc\", \"warnings\", \"scipy\", \"numpy\", \"pandas\", \"tqdm\", \"itertools\",\n",
    "    \"os\", \"random\", \"joblib\", \"lightgbm\", \"sklearn\"\n",
    "]\n",
    "\n",
    "print(\"Checking Python libraries:\")\n",
    "for lib in required_libraries:\n",
    "    try:\n",
    "        importlib.import_module(lib)\n",
    "        print(f\"✅ {lib} is installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"❌ {lib} is NOT installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2360ad2",
   "metadata": {
    "papermill": {
     "duration": 0.00503,
     "end_time": "2022-07-20T12:57:40.471210",
     "exception": false,
     "start_time": "2022-07-20T12:57:40.466180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ca6c8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.186694,
     "end_time": "2022-07-20T12:57:40.661148",
     "exception": false,
     "start_time": "2022-07-20T12:57:40.474454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training feature engineer...\n",
      "1\n",
      "2\n",
      "Starting test feature engineer...\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "Data preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "# ====================================================\n",
    "# Read & preprocess data and save it to disk\n",
    "# ====================================================\n",
    "def read_preprocess_data():\n",
    "    train = pd.read_parquet('content/data/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    print(\"1\")\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    train_labels = pd.read_csv('content/data/train_labels.csv')\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg\n",
    "    gc.collect()\n",
    "    print(\"2\")\n",
    "    test = pd.read_parquet('content/data/test.parquet')\n",
    "    print('Starting test feature engineer...')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "    print(\"3\")\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    print(\"4\")\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg\n",
    "    print(\"5\")\n",
    "    gc.collect()\n",
    "    # Save files to disk\n",
    "    train.to_parquet('content/data/train_fe.parquet')\n",
    "    print(\"6\")\n",
    "    test.to_parquet('content/data/test_fe.parquet')\n",
    "    print(\"Data preprocessing complete!\")\n",
    "\n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "509f5d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 920)\n",
      "                                         customer_ID  P_2_mean   P_2_std   P_2_min   P_2_max  P_2_last  D_39_mean  D_39_std  D_39_min  D_39_max  D_39_last  B_1_mean   B_1_std   B_1_min   B_1_max  B_1_last  B_2_mean   B_2_std   B_2_min   B_2_max  B_2_last  R_1_mean   R_1_std   R_1_min   R_1_max  R_1_last  S_3_mean   S_3_std   S_3_min   S_3_max  S_3_last  D_41_mean  D_41_std  D_41_min  D_41_max  D_41_last  B_3_mean   B_3_std   B_3_min   B_3_max  B_3_last  D_42_mean  D_42_std  D_42_min  D_42_max  D_42_last  D_43_mean  D_43_std  D_43_min  D_43_max  D_43_last  D_44_mean  D_44_std  D_44_min  D_44_max  D_44_last   B_4_mean   B_4_std  B_4_min  B_4_max  B_4_last  D_45_mean  D_45_std  D_45_min  D_45_max  D_45_last  B_5_mean   B_5_std   B_5_min   B_5_max  B_5_last  R_2_mean  R_2_std  R_2_min  R_2_max  R_2_last  D_46_mean  D_46_std  D_46_min  D_46_max  D_46_last  D_47_mean  D_47_std  D_47_min  D_47_max  D_47_last  D_48_mean  D_48_std  D_48_min  D_48_max  D_48_last  D_49_mean  D_49_std  D_49_min  \\\n",
      "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.933824  0.024194  0.868580  0.960384  0.934745   0.230769  0.832050         0         3          0  0.012007  0.006547  0.001930  0.021655  0.009382  1.005086  0.003222  1.000242  1.009672  1.007647  0.004509  0.003081  0.000263  0.009228  0.006104  0.113215  0.011670  0.098882  0.135021  0.135021        0.0       0.0       0.0       0.0        0.0  0.006456  0.002942  0.000783  0.009866  0.007174        NaN       NaN       NaN       NaN        NaN        NaN       NaN       NaN       NaN        NaN   0.000000   0.00000         0         0          0   2.846154  2.444250        0        6         5   0.725369  0.009515  0.708906  0.740102   0.740102  0.146650  0.047205  0.060492  0.231717  0.231717       0.0      0.0        0        0         0   0.378074  0.085674  0.231009  0.519619   0.420521   0.532874  0.006578  0.521311  0.542119   0.539715   0.240978  0.076875  0.135586  0.403448   0.192376       -1.0       0.0        -1   \n",
      "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...  0.899820  0.022119  0.861109  0.929122  0.880519   7.153846  6.743468         0        19          6  0.025654  0.027756  0.006711  0.109644  0.034684  0.991083  0.051531  0.819772  1.008534  1.004028  0.006246  0.002129  0.001023  0.008996  0.006911  0.120578  0.023824  0.089799  0.165509  0.165509        0.0       0.0       0.0       0.0        0.0  0.005663  0.003354  0.000861  0.012861  0.005068        NaN       NaN       NaN       NaN        NaN   0.144571  0.169598  0.060646  0.525600   0.060646   0.000000   0.00000         0         0          0   0.846154  0.800641        0        3         1   0.256461  0.009261  0.239459  0.267228   0.266275  0.035462  0.043899  0.004075  0.165146  0.027000       0.0      0.0        0        0         0   0.452041  0.013177  0.432424  0.471737   0.438828   0.392433  0.006671  0.382562  0.402878   0.402195   0.048203  0.031312  0.010117  0.105999   0.014696       -1.0       0.0        -1   \n",
      "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...  0.878454  0.028911  0.797670  0.904482  0.880875   0.000000  0.000000         0         0          0  0.004386  0.002786  0.001472  0.009997  0.004284  0.815677  0.003545  0.810796  0.819987  0.812649  0.006621  0.001919  0.003540  0.009443  0.006450       NaN       NaN       NaN       NaN       NaN        0.0       0.0       0.0       0.0        0.0  0.005493  0.002834  0.000626  0.009383  0.007196        NaN       NaN       NaN       NaN        NaN        NaN       NaN       NaN       NaN        NaN   0.076923   0.27735         0         1          0   2.230769  1.690850        1        7         2   0.236871  0.008896  0.222406  0.251598   0.251598  0.004618  0.003043  0.000215  0.008656  0.001557       0.0      0.0        0        0         0   0.464475  0.060166  0.413028  0.647064   0.433713   0.328617  0.007183  0.318290  0.339566   0.339125   0.092284  0.060616  0.030227  0.255134   0.080370       -1.0       0.0        -1   \n",
      "3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...  0.598969  0.020107  0.567442  0.623392  0.621776   1.538462  3.017046         0         9          0  0.059876  0.080531  0.005910  0.279991  0.012564  0.955264  0.080981  0.812053  1.009999  1.006183  0.005665  0.003473  0.000199  0.009915  0.007829  0.247750  0.095122  0.149216  0.407420  0.287766        0.0       0.0       0.0       0.0        0.0  0.006423  0.003360  0.000053  0.010927  0.009937        NaN       NaN       NaN       NaN        NaN   0.061026  0.041993  0.006633  0.149891   0.046104   0.000000   0.00000         0         0          0   2.230769  2.832956        0        8         0   0.069334  0.008501  0.056394  0.085103   0.085103  0.088374  0.074462  0.000228  0.283781  0.118818       0.0      0.0        0        0         0   0.431905  0.030525  0.384254  0.471676   0.410723   0.403269  0.006355  0.392230  0.414224   0.414224   0.076686  0.063902  0.005276  0.177252   0.013057       -1.0       0.0        -1   \n",
      "4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...  0.891679  0.042325  0.805045  0.940382  0.871900   0.000000  0.000000         0         0          0  0.005941  0.002475  0.000776  0.009806  0.007679  0.814543  0.003143  0.810670  0.819947  0.815746  0.004180  0.002581  0.000336  0.009076  0.001247  0.173102  0.004669  0.166190  0.176403  0.176403        0.0       0.0       0.0       0.0        0.0  0.005088  0.002910  0.000049  0.009686  0.005528        NaN       NaN       NaN       NaN        NaN   0.048778  0.006847  0.037001  0.061963   0.044671   0.000000   0.00000         0         0          0  11.692308  9.384248        3       25        21   0.209150  0.117203  0.063150  0.305305   0.069952  0.004572  0.002297  0.001201  0.007830  0.004855       0.0      0.0        0        0         0   0.474523  0.076167  0.366783  0.694332   0.465525   0.471961  0.007588  0.461473  0.484715   0.480303   0.253697  0.093176  0.137840  0.491528   0.325121       -1.0       0.0        -1   \n",
      "\n",
      "   D_49_max  D_49_last  B_6_mean   B_6_std   B_6_min   B_6_max  B_6_last  B_7_mean   B_7_std   B_7_min   B_7_max  B_7_last  B_8_mean   B_8_std   B_8_min   B_8_max  B_8_last  D_50_mean  D_50_std  D_50_min  D_50_max  D_50_last  D_51_mean  D_51_std  D_51_min  D_51_max  D_51_last  B_9_mean   B_9_std   B_9_min   B_9_max  B_9_last  R_3_mean   R_3_std  R_3_min  R_3_max  R_3_last  D_52_mean  D_52_std  D_52_min  D_52_max  D_52_last  P_3_mean   P_3_std   P_3_min   P_3_max  P_3_last  B_10_mean  B_10_std  B_10_min  B_10_max  B_10_last  D_53_mean  D_53_std  D_53_min  D_53_max  D_53_last  S_5_mean   S_5_std   S_5_min   S_5_max  S_5_last  B_11_mean  B_11_std  B_11_min  B_11_max  B_11_last  S_6_mean   S_6_std  S_6_min  S_6_max  S_6_last  D_54_mean  D_54_std  D_54_min  D_54_max  D_54_last  R_4_mean  R_4_std  R_4_min  R_4_max  R_4_last  S_7_mean   S_7_std   S_7_min   S_7_max  S_7_last  B_12_mean  B_12_std  B_12_min  B_12_max  B_12_last     S_8_mean     S_8_std  S_8_min  S_8_max  S_8_last  D_55_mean  \\\n",
      "0        -1         -1  0.113510  0.047360  0.063902  0.221899  0.149564  0.036624  0.023195  0.001681  0.060502  0.058425  0.000000  0.000000  0.000000  0.000000  0.000000   0.150326  0.002922  0.145179  0.154326   0.153461   2.923077  0.954074         2         4          2  0.006220  0.003180  0.000519  0.009535  0.009535  0.000000  0.000000        0        0         0   0.204972  0.002400  0.200782  0.208214   0.203524  0.680138  0.050671  0.581678  0.741813  0.629392   0.270280  0.181875  0.096219  0.741934   0.326101        NaN       NaN       NaN       NaN        NaN  0.029112  0.014758  0.007165  0.054221  0.034643   0.007230  0.003031  0.002749  0.010260   0.010260  0.000000  0.000000        0        0         0        1.0       0.0       1.0       1.0        1.0       0.0      0.0        0        0         0  0.098374  0.026775  0.074646  0.161345  0.105671   0.125683  0.011772  0.111060  0.148266   0.112294  2510.000000  429.583519     1544     3166      1544   0.224432   \n",
      "1        -1         -1  0.202270  0.015915  0.167634  0.226641  0.167634  0.028049  0.013631  0.015836  0.068204  0.028411  0.000000  0.000000  0.000000  0.000000  0.000000        NaN       NaN       NaN       NaN        NaN   1.153846  0.375534         1         2          1  0.010298  0.011024  0.001722  0.045093  0.012926  0.538462  0.518875        0        1         1   0.158313  0.067030  0.103495  0.242366   0.242366  0.566665  0.036880  0.510142  0.619012  0.570898   0.298815  0.003047  0.294000  0.302757   0.297130        NaN       NaN       NaN       NaN        NaN  0.016785  0.017104  0.002045  0.052949  0.043929   0.013792  0.021041  0.000416  0.081246   0.014570  0.000000  0.000000        0        0         0        1.0       0.0       1.0       1.0        1.0       0.0      0.0        0        0         0  0.103002  0.035143  0.072583  0.208516  0.208516   0.025823  0.004665  0.019050  0.032917   0.019050  1286.461538  772.374544        0     2402      1284   0.048069   \n",
      "2        -1         -1  0.176674  0.024615  0.129857  0.213943  0.183628  0.034433  0.015459  0.021261  0.079764  0.026981  0.000000  0.000000  0.000000  0.000000  0.000000        NaN       NaN       NaN       NaN        NaN   0.615385  0.506370         0         1          1  0.004730  0.003302  0.000422  0.009521  0.009392  0.000000  0.000000        0        0         0   0.199863  0.002990  0.195188  0.203649   0.202159  0.618191  0.075604  0.381123  0.678706  0.628938   0.273711  0.052875  0.162125  0.302619   0.296313        NaN       NaN       NaN       NaN        NaN  0.005948  0.002943  0.001054  0.008730  0.001824   0.004683  0.002312  0.000111  0.007619   0.005092  1.000000  0.000000        1        1         1        1.0       0.0       1.0       1.0        1.0       0.0      0.0        0        0         0       NaN       NaN       NaN       NaN       NaN   0.011541  0.002969  0.006100  0.015486   0.007158     0.000000    0.000000        0        0         0   0.077362   \n",
      "3        -1         -1  0.160625  0.031266  0.079987  0.196887  0.174331  0.062130  0.073590  0.004301  0.252338  0.011969  1.004676  0.001928  1.002021  1.008767  1.005561   0.439581  0.044539  0.341256  0.482535   0.430318   0.076923  0.277350         0         1          1  0.052241  0.053342  0.001702  0.176352  0.020526  0.615385  0.650444        0        2         2   0.199698  0.002130  0.195300  0.203203   0.198356  0.610934  0.090090  0.345100  0.704214  0.672080   0.306553  0.079528  0.192981  0.431901   0.411625   0.004336  0.003589  0.000346   0.00999   0.001379  0.056297  0.044583  0.002999  0.150845  0.022970   0.044294  0.071076  0.000672  0.241378   0.005491  0.000000  0.000000        0        0         0        1.0       0.0       1.0       1.0        1.0       0.0      0.0        0        0         0  0.261497  0.078128  0.152622  0.370595  0.279464   0.048949  0.025280  0.009411  0.077831   0.074835   961.307692  405.585048      528     1511       528   0.061726   \n",
      "4        -1         -1  0.075672  0.046857  0.030852  0.195757  0.048857  0.115290  0.070823  0.035662  0.216773  0.159818  0.386868  0.509339  0.000000  1.008826  1.005185   0.093218  0.020103  0.073834  0.136212   0.095238   0.153846  0.375534         0         1          0  0.006685  0.002242  0.002925  0.009847  0.004027  0.153846  0.375534        0        1         0   0.233470  0.028414  0.191802  0.256440   0.253811  0.527254  0.088509  0.254276  0.584359  0.570419   0.100315  0.074579  0.044728  0.260673   0.125195        NaN       NaN       NaN       NaN        NaN  0.005051  0.002665  0.002389  0.009350  0.009350   0.005017  0.003694  0.000714  0.009807   0.001001  0.846154  0.375534        0        1         1        1.0       0.0       1.0       1.0        1.0       0.0      0.0        0        0         0  0.120290  0.008589  0.108082  0.128201  0.122915   0.049640  0.060154  0.005756  0.151135   0.013041   157.076923  383.420018        0     1021         0   0.203298   \n",
      "\n",
      "   D_55_std  D_55_min  D_55_max  D_55_last  D_56_mean  D_56_std  D_56_min  D_56_max  D_56_last  B_13_mean  B_13_std  B_13_min  B_13_max  B_13_last  R_5_mean  R_5_std  R_5_min  R_5_max  R_5_last  D_58_mean  D_58_std  D_58_min  D_58_max  D_58_last  S_9_mean   S_9_std   S_9_min   S_9_max  S_9_last  B_14_mean  B_14_std  B_14_min  B_14_max  B_14_last  D_59_mean  D_59_std  D_59_min  D_59_max  D_59_last  D_60_mean  D_60_std  D_60_min  D_60_max  D_60_last  D_61_mean  D_61_std  D_61_min  D_61_max  D_61_last  B_15_mean  B_15_std  B_15_min  B_15_max  B_15_last  S_11_mean  S_11_std  S_11_min  S_11_max  ...  D_107_last  B_36_mean  B_36_std  B_36_min  B_36_max  B_36_last  B_37_mean  B_37_std  B_37_min  B_37_max  B_37_last  R_26_mean  R_26_std  R_26_min  R_26_max  R_26_last  R_27_mean  R_27_std  R_27_min  R_27_max  R_27_last  D_108_mean  D_108_std  D_108_min  D_108_max  D_108_last  D_109_mean  D_109_std  D_109_min  D_109_max  D_109_last  D_110_mean  D_110_std  D_110_min  D_110_max  D_110_last  \\\n",
      "0  0.068116  0.148284  0.354596   0.187285   0.158571  0.004747  0.152025  0.166636   0.166636   0.100432  0.013723  0.074886  0.120740   0.100107       0.0      0.0        0        0         0   0.064803  0.069456  0.000267  0.158612   0.007174  0.039818  0.026706  0.007397  0.093935  0.007397   0.023142  0.013715  0.009725  0.056653   0.010239   7.769231  0.438529         7         8          8   0.534817  0.392130  0.141639  1.009424   0.258461   0.225847  0.071863  0.121276  0.383477   0.227637   0.026247  0.016911  0.007219  0.063955   0.014553  16.615385  1.660244        15        19  ...           2   0.005292  0.003333  0.001264  0.009998   0.007441   0.012015  0.006662  0.004566  0.025011   0.008676       -1.0       0.0        -1        -1         -1   1.005594  0.003127  1.000246  1.009108   1.006130        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         NaN        NaN        NaN        NaN         NaN   \n",
      "1  0.007596  0.036112  0.060770   0.036112   0.705671  0.018540  0.684371  0.748383   0.748383   0.046753  0.024456  0.008499  0.073904   0.017684       0.0      0.0        0        0         0   0.005146  0.002801  0.000004  0.009756   0.009756  0.033809  0.052705  0.006782  0.127805  0.127805   0.014848  0.014395  0.001797  0.057174   0.018667  15.923077  0.277350        15        16         15   0.326530  0.221335  0.059118  0.857541   0.411989   0.053319  0.030845  0.015966  0.103947   0.048978   0.005560  0.002920  0.000095  0.009642   0.009538  14.230769  3.244324        10        23  ...           0   0.006088  0.002787  0.001115  0.009940   0.007457   0.025244  0.027278  0.002606  0.105623   0.032899       -1.0       0.0        -1        -1         -1   1.005984  0.003487  1.000630  1.009615   1.007599        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         NaN        NaN        NaN        NaN         NaN   \n",
      "2  0.016318  0.057529  0.099230   0.098963   0.208154  0.003188  0.201530  0.211538   0.209386   0.003778  0.002688  0.000427  0.008332   0.001749       0.0      0.0        0        0         0   0.023569  0.037544  0.000726  0.093983   0.002847       NaN       NaN       NaN       NaN       NaN   0.004729  0.003074  0.000684  0.008507   0.006699  15.923077  0.277350        15        16         15   0.004735  0.002602  0.000553  0.008550   0.002820   0.109526  0.061762  0.040357  0.249231   0.137834   0.004716  0.002986  0.000019  0.009969   0.006031  12.000000  0.000000        12        12  ...           0   0.004093  0.002501  0.000386  0.008693   0.005196   0.004545  0.003195  0.000300  0.009954   0.004723       -1.0       0.0        -1        -1         -1   1.004953  0.002969  1.000931  1.009937   1.003010        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         NaN        NaN        NaN        NaN         NaN   \n",
      "3  0.018374  0.021400  0.094076   0.021400   0.564632  0.018147  0.533675  0.580167   0.554483   0.081928  0.041875  0.013755  0.124311   0.055897       0.0      0.0        0        0         0   0.023349  0.034747  0.000053  0.088388   0.009294  0.016887  0.008305  0.005059  0.031257  0.011429   0.033350  0.029768  0.006169  0.103393   0.017101  26.538462  2.025479        24        29         29   0.673302  0.331873  0.081805  1.008510   0.394758   0.066872  0.050442  0.026844  0.171638   0.026844   0.004382  0.003003  0.000218  0.009221   0.002199  12.461538  1.664101        10        14  ...           0   0.004650  0.003275  0.000348  0.009266   0.004745   0.058964  0.080873  0.005646  0.282233   0.007375       -1.0       0.0        -1        -1         -1   1.005059  0.002681  1.000463  1.009452   1.004479        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         NaN        NaN        NaN        NaN         NaN   \n",
      "4  0.041725  0.125503  0.254067   0.254067   0.178482  0.009615  0.163719  0.190924   0.183075   0.004422  0.002974  0.000626  0.008859   0.006051       0.0      0.0        0        0         0   0.318151  0.102317  0.094102  0.392473   0.382744       NaN       NaN       NaN       NaN       NaN   0.004924  0.003445  0.000025  0.009628   0.009469  23.153846  3.715870        18        28         28   0.003476  0.002267  0.000846  0.009551   0.002670   0.356445  0.255848  0.082395  0.715081   0.600739   0.006005  0.002529  0.001513  0.009890   0.005842  12.538462  1.391365        12        17  ...           3   0.004333  0.003532  0.000127  0.009628   0.002269   0.004030  0.003199  0.000415  0.009483   0.007787       -1.0       0.0        -1        -1         -1   1.005777  0.002360  1.001764  1.009596   1.006920        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         NaN        NaN        NaN        NaN         NaN   \n",
      "\n",
      "   D_111_mean  D_111_std  D_111_min  D_111_max  D_111_last  B_39_mean  B_39_std  B_39_min  B_39_max  B_39_last  D_112_mean  D_112_std  D_112_min  D_112_max  D_112_last  B_40_mean  B_40_std  B_40_min  B_40_max  B_40_last  S_27_mean  S_27_std  S_27_min  S_27_max  S_27_last  D_113_mean  D_113_std  D_113_min  D_113_max  D_113_last  D_115_mean  D_115_std  D_115_min  D_115_max  D_115_last  D_118_mean  D_118_std  D_118_min  D_118_max  D_118_last  D_119_mean  D_119_std  D_119_min  D_119_max  D_119_last  D_121_mean  D_121_std  D_121_min  D_121_max  D_121_last  D_122_mean  D_122_std  D_122_min  D_122_max  D_122_last  D_123_mean  D_123_std  D_123_min  D_123_max  D_123_last  D_124_mean  D_124_std  D_124_min  D_124_max  D_124_last  D_125_mean  D_125_std  D_125_min  D_125_max  D_125_last  D_127_mean  D_127_std  D_127_min  D_127_max  D_127_last  D_128_mean  D_128_std  D_128_min  D_128_max  D_128_last  D_129_mean  D_129_std  D_129_min  D_129_max  D_129_last  B_41_mean  B_41_std  B_41_min  B_41_max  \\\n",
      "0        -1.0        0.0         -1         -1          -1        NaN       NaN       NaN       NaN        NaN    1.000000   0.000000   1.000000        1.0         1.0   0.087300  0.075566  0.001404  0.210060   0.100454   0.850951  0.077817  0.676922  0.979416   0.928955         0.0        0.0          0          0           0    0.247095   0.006530   0.238250   0.256733    0.255787    0.245514   0.007778   0.232120   0.260255    0.260255    0.244733   0.005283   0.236266   0.256656    0.256656    0.711829   0.005898   0.702280   0.719791    0.719791    3.000000   0.000000          3          3           3         0.0        0.0          0          0           0   16.000000   0.000000         16         16          16         0.0        0.0          0          0           0    1.000000    0.00000          1          1           1    1.004154   0.003293   0.999530   1.008219    0.999737         1.0        0.0          1          1           1        0.0       0.0         0         0   \n",
      "1        -1.0        0.0         -1         -1          -1        NaN       NaN       NaN       NaN        NaN    1.000000   0.000000   1.000000        1.0         1.0   0.022125  0.006794  0.013852  0.032634   0.019811   0.133975  0.160302  0.001245  0.341470   0.292214         0.0        0.0          0          0           0    0.439431   0.008210   0.430118   0.454329    0.454329    0.433039   0.007200   0.418370   0.446036    0.446036    0.430961   0.008279   0.416349   0.444072    0.436884    0.535892   0.006430   0.526699   0.551341    0.551341    2.000000   0.000000          2          2           2         0.0        0.0          0          0           0    4.000000   0.000000          4          4           4         0.0        0.0          0          0           0    0.076923    0.27735          0          1           0    1.002631   0.002154   0.999250   1.006768    0.999252         0.0        0.0          0          0           0        0.0       0.0         0         0   \n",
      "2        -1.0        0.0         -1         -1          -1        NaN       NaN       NaN       NaN        NaN    1.000000   0.000000   1.000000        1.0         1.0   0.027405  0.014825  0.009921  0.068245   0.024902        NaN       NaN       NaN       NaN        NaN         0.0        0.0          0          0           0    0.380367   0.006444   0.368565   0.389195    0.388621    0.354381   0.007042   0.345541   0.368051    0.368051    0.354291   0.009090   0.338230   0.369018    0.369018    0.431903   0.007018   0.419969   0.444615    0.444615    1.000000   0.000000          1          1           1         0.0        0.0          0          0           0    7.000000   0.000000          7          7           7         0.0        0.0          0          0           0    0.000000    0.00000          0          0           0    0.000000   0.000000   0.000000   0.000000    0.000000         0.0        0.0          0          0           0        0.0       0.0         0         0   \n",
      "3        -1.0        0.0         -1         -1          -1        NaN       NaN       NaN       NaN        NaN    0.618476   0.502302   0.005729        1.0         1.0   0.073795  0.105462  0.000022  0.316919   0.031024   0.515847  0.177004  0.009429  0.680603   0.680603         1.0        0.0          1          1           1    0.152994   0.195984   0.039396   0.499835    0.059353    0.048511   0.007280   0.036688   0.059829    0.058773    0.046677   0.008728   0.032145   0.062736    0.062736    0.621386   0.006768   0.613962   0.632540    0.629147    2.230769   0.438529          2          3           2         0.0        0.0          0          0           0   14.230769   0.438529         14         15          14         0.0        0.0          0          0           0    0.000000    0.00000          0          0           0    1.003734   0.002775   0.999873   1.008289    1.002651         1.0        0.0          1          1           1        0.0       0.0         0         0   \n",
      "4        -1.0        0.0         -1         -1          -1        NaN       NaN       NaN       NaN        NaN    1.000000   0.000000   1.000000        1.0         1.0   0.149035  0.053852  0.040987  0.211423   0.116816        NaN       NaN       NaN       NaN        NaN         0.0        0.0          0          0           0    0.434215   0.008094   0.425165   0.448481    0.448481    0.426588   0.007816   0.418822   0.442338    0.442338    0.426044   0.007038   0.412775   0.437632    0.436173    0.550940   0.007753   0.542339   0.565815    0.565815    3.000000   0.000000          3          3           3         0.0        0.0          0          0           0    5.000000   0.000000          5          5           5         0.0        0.0          0          0           0    0.000000    0.00000          0          0           0    1.004544   0.002427   0.999943   1.007347    1.006172         1.0        0.0          1          1           1        0.0       0.0         0         0   \n",
      "\n",
      "   B_41_last  B_42_mean  B_42_std  B_42_min  B_42_max  B_42_last  D_130_mean  D_130_std  D_130_min  D_130_max  D_130_last  D_131_mean  D_131_std  D_131_min  D_131_max  D_131_last  D_132_mean  D_132_std  D_132_min  D_132_max  D_132_last  D_133_mean  D_133_std  D_133_min  D_133_max  D_133_last  R_28_mean  R_28_std  R_28_min  R_28_max  R_28_last  D_134_mean  D_134_std  D_134_min  D_134_max  D_134_last  D_135_mean  D_135_std  D_135_min  D_135_max  D_135_last  D_136_mean  D_136_std  D_136_min  D_136_max  D_136_last  D_137_mean  D_137_std  D_137_min  D_137_max  D_137_last  D_138_mean  D_138_std  D_138_min  D_138_max  D_138_last  D_139_mean  D_139_std  D_139_min  D_139_max  D_139_last  D_140_mean  D_140_std  D_140_min  D_140_max  D_140_last  D_141_mean  D_141_std  D_141_min  D_141_max  D_141_last  D_142_mean  D_142_std  D_142_min  D_142_max  D_142_last  D_143_mean  D_143_std  D_143_min  D_143_max  D_143_last  D_144_mean  D_144_std  D_144_min  D_144_max  D_144_last  D_145_mean  D_145_std  \\\n",
      "0          0        NaN       NaN       NaN       NaN        NaN      0.0000   0.000000   0.000000   0.000000    0.000000         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN    0.004760   0.003116   0.000122   0.009227    0.006210        0.0       0.0         0         0          0         NaN        NaN        NaN        NaN         NaN        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         0.0        0.0          0          0           0         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN         0.0        0.0          0          0           0    0.005283   0.002598   0.000610   0.009616    0.002970         0.0        0.0   \n",
      "1          0        NaN       NaN       NaN       NaN        NaN      0.0000   0.000000   0.000000   0.000000    0.000000         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN    0.004519   0.002616   0.001289   0.009592    0.002996        0.0       0.0         0         0          0         NaN        NaN        NaN        NaN         NaN        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         0.0        0.0          0          0           0         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN         0.0        0.0          0          0           0    0.004218   0.002871   0.000027   0.009568    0.003169         0.0        0.0   \n",
      "2          0        NaN       NaN       NaN       NaN        NaN      0.0000   0.000000   0.000000   0.000000    0.000000         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN    0.006781   0.002809   0.001980   0.009881    0.009881        0.0       0.0         0         0          0         NaN        NaN        NaN        NaN         NaN        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         0.0        0.0          0          0           0         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN         0.0        0.0          0          0           0    0.005113   0.003638   0.000129   0.009415    0.000834         0.0        0.0   \n",
      "3          0        NaN       NaN       NaN       NaN        NaN      0.0000   0.000000   0.000000   0.000000    0.000000         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN    0.003369   0.002539   0.000591   0.009528    0.001789        0.0       0.0         0         0          0         NaN        NaN        NaN        NaN         NaN        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         0.0        0.0          0          0           0         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN         0.0        0.0          0          0           0    0.004768   0.002654   0.000492   0.009919    0.005560         0.0        0.0   \n",
      "4          0        NaN       NaN       NaN       NaN        NaN      1.0055   0.002575   1.001736   1.008879    1.006119         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN    0.004744   0.002777   0.001776   0.009534    0.005045        0.0       0.0         0         0          0         NaN        NaN        NaN        NaN         NaN        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         0.0        0.0          0          0           0         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN         0.0        0.0          0          0           0    0.004380   0.002633   0.000633   0.009436    0.006944         0.0        0.0   \n",
      "\n",
      "   D_145_min  D_145_max  D_145_last  B_30_count  B_30_last  B_30_nunique  B_38_count  B_38_last  B_38_nunique  D_114_count  D_114_last  D_114_nunique  D_116_count  D_116_last  D_116_nunique  D_117_count  D_117_last  D_117_nunique  D_120_count  D_120_last  D_120_nunique  D_126_count  D_126_last  D_126_nunique  D_63_count  D_63_last  D_63_nunique  D_64_count  D_64_last  D_64_nunique  D_66_count  D_66_last  D_66_nunique  D_68_count  D_68_last  D_68_nunique  target  \n",
      "0          0          0           0          13          0             1          13          2             1           13           1              1           13           0              1           13           5              1           13           0              1           13           2              1          13          0             1          13          0             1          13         -1             1          13          6             1       0  \n",
      "1          0          0           0          13          0             1          13          2             1           13           1              1           13           0              1           13           0              1           13           0              2           13           2              1          13          3             1          13          0             1          13         -1             1          13          6             1       0  \n",
      "2          0          0           0          13          0             1          13          1             1           13           1              2           13           0              1           13           0              1           13           0              1           13           2              1          13          3             1          13          2             1          13         -1             1          13          6             1       0  \n",
      "3          0          0           0          13          0             1          13          2             1           13           1              1           13           0              1           13           7              2           13           0              1           13           2              1          13          3             1          13          0             1          13         -1             1          13          3             3       0  \n",
      "4          0          0           0          13          0             1          13          1             2           13           1              1           13           0              1           13           5              1           13           0              1           13           2              1          13          3             1          13          0             1          13          1             1          13          6             1       0  \n",
      "\n",
      "[5 rows x 920 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_parquet('content/data/train_fe.parquet')\n",
    "print(test_df.shape)  # Shows the (rows, columns) of the DataFrame\n",
    "print(test_df.head()) # Displays the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0283f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LightGBM GPU support is ENABLED.\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "def check_lightgbm_gpu():\n",
    "    try:\n",
    "        X = np.random.rand(50, 2)\n",
    "        y = np.random.randint(0, 2, 50)\n",
    "        dtrain = lgb.Dataset(X, label=y)\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'device': 'gpu',  # Try using GPU\n",
    "            'verbose': -1,\n",
    "            'num_iterations': 1\n",
    "        }\n",
    "        lgb.train(params, dtrain)\n",
    "        print(\"✅ LightGBM GPU support is ENABLED.\")\n",
    "    except Exception as e:\n",
    "        print(\"❌ LightGBM GPU support is NOT enabled.\")\n",
    "        print(\"Error message:\", e)\n",
    "\n",
    "check_lightgbm_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c59c9073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM version: 4.6.0\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "print(\"LightGBM version:\", lightgbm.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "158908d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 23 11:18:20 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 572.83                 Driver Version: 572.83         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650 ...  WDDM  |   00000000:02:00.0 Off |                  N/A |\n",
      "| N/A   49C    P0             13W /   35W |       0MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    output = subprocess.check_output('nvidia-smi', encoding='utf-8')\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(\"No Nvidia GPU detected or drivers not installed.\")\n",
    "    print(\"Error message:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45867f77",
   "metadata": {
    "papermill": {
     "duration": 0.009399,
     "end_time": "2022-07-20T12:57:40.688278",
     "exception": false,
     "start_time": "2022-07-20T12:57:40.678879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0090e82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T12:57:40.702186Z",
     "iopub.status.busy": "2022-07-20T12:57:40.701682Z",
     "iopub.status.idle": "2022-07-20T12:57:44.381312Z",
     "shell.execute_reply": "2022-07-20T12:57:44.380332Z"
    },
    "papermill": {
     "duration": 3.689383,
     "end_time": "2022-07-20T12:57:44.383869",
     "exception": false,
     "start_time": "2022-07-20T12:57:40.694486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU device: NVIDIA GeForce GTX 1650 with Max-Q Design on platform: NVIDIA CUDA\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1011 features...\n",
      "[LightGBM] [Info] Number of positive: 59414, number of negative: 170042\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 47730\n",
      "[LightGBM] [Info] Number of data points in the train set: 229456, number of used features: 1002\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1650 with Max-Q Design, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 555 dense feature groups (121.67 MB) transferred to GPU in 0.093427 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258934 -> initscore=-1.051516\n",
      "[LightGBM] [Info] Start training from score -1.051516\n",
      "[500]\ttraining's binary_logloss: 0.336527\ttraining's amex_metric: 0.781481\tvalid_1's binary_logloss: 0.339848\tvalid_1's amex_metric: 0.766811\n",
      "[1000]\ttraining's binary_logloss: 0.244167\ttraining's amex_metric: 0.80068\tvalid_1's binary_logloss: 0.253084\tvalid_1's amex_metric: 0.77766\n",
      "[1500]\ttraining's binary_logloss: 0.218329\ttraining's amex_metric: 0.817353\tvalid_1's binary_logloss: 0.233033\tvalid_1's amex_metric: 0.783884\n",
      "[2000]\ttraining's binary_logloss: 0.20296\ttraining's amex_metric: 0.833425\tvalid_1's binary_logloss: 0.224608\tvalid_1's amex_metric: 0.788243\n",
      "[2500]\ttraining's binary_logloss: 0.194757\ttraining's amex_metric: 0.845866\tvalid_1's binary_logloss: 0.222056\tvalid_1's amex_metric: 0.789747\n",
      "[3000]\ttraining's binary_logloss: 0.186366\ttraining's amex_metric: 0.857776\tvalid_1's binary_logloss: 0.219982\tvalid_1's amex_metric: 0.791514\n",
      "[3500]\ttraining's binary_logloss: 0.178579\ttraining's amex_metric: 0.870334\tvalid_1's binary_logloss: 0.218688\tvalid_1's amex_metric: 0.792855\n",
      "[4000]\ttraining's binary_logloss: 0.171693\ttraining's amex_metric: 0.881748\tvalid_1's binary_logloss: 0.21791\tvalid_1's amex_metric: 0.793743\n",
      "[4500]\ttraining's binary_logloss: 0.165002\ttraining's amex_metric: 0.89352\tvalid_1's binary_logloss: 0.217312\tvalid_1's amex_metric: 0.794465\n",
      "[5000]\ttraining's binary_logloss: 0.158361\ttraining's amex_metric: 0.905117\tvalid_1's binary_logloss: 0.216908\tvalid_1's amex_metric: 0.794928\n",
      "[5500]\ttraining's binary_logloss: 0.152491\ttraining's amex_metric: 0.915307\tvalid_1's binary_logloss: 0.216672\tvalid_1's amex_metric: 0.795376\n",
      "[6000]\ttraining's binary_logloss: 0.147493\ttraining's amex_metric: 0.923716\tvalid_1's binary_logloss: 0.216512\tvalid_1's amex_metric: 0.79519\n",
      "[6500]\ttraining's binary_logloss: 0.142281\ttraining's amex_metric: 0.931138\tvalid_1's binary_logloss: 0.216351\tvalid_1's amex_metric: 0.79523\n",
      "[7000]\ttraining's binary_logloss: 0.136365\ttraining's amex_metric: 0.940263\tvalid_1's binary_logloss: 0.216181\tvalid_1's amex_metric: 0.795319\n",
      "[7500]\ttraining's binary_logloss: 0.130789\ttraining's amex_metric: 0.948416\tvalid_1's binary_logloss: 0.216113\tvalid_1's amex_metric: 0.795927\n",
      "[8000]\ttraining's binary_logloss: 0.125873\ttraining's amex_metric: 0.955177\tvalid_1's binary_logloss: 0.216094\tvalid_1's amex_metric: 0.795717\n",
      "[8500]\ttraining's binary_logloss: 0.121701\ttraining's amex_metric: 0.961395\tvalid_1's binary_logloss: 0.216071\tvalid_1's amex_metric: 0.795907\n",
      "[9000]\ttraining's binary_logloss: 0.117048\ttraining's amex_metric: 0.96723\tvalid_1's binary_logloss: 0.216144\tvalid_1's amex_metric: 0.79565\n",
      "[9500]\ttraining's binary_logloss: 0.112908\ttraining's amex_metric: 0.972197\tvalid_1's binary_logloss: 0.216156\tvalid_1's amex_metric: 0.795823\n",
      "[10000]\ttraining's binary_logloss: 0.108903\ttraining's amex_metric: 0.976864\tvalid_1's binary_logloss: 0.216212\tvalid_1's amex_metric: 0.795271\n",
      "[10500]\ttraining's binary_logloss: 0.105432\ttraining's amex_metric: 0.980362\tvalid_1's binary_logloss: 0.216298\tvalid_1's amex_metric: 0.795157\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 179\u001b[0m\n\u001b[0;32m    177\u001b[0m seed_everything(CFG\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m    178\u001b[0m train, test \u001b[38;5;241m=\u001b[39m read_data()\n\u001b[1;32m--> 179\u001b[0m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 154\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(train, test)\u001b[0m\n\u001b[0;32m    142\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m    143\u001b[0m     params \u001b[38;5;241m=\u001b[39m params,\n\u001b[0;32m    144\u001b[0m     train_set \u001b[38;5;241m=\u001b[39m lgb_train,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    151\u001b[0m                lgb\u001b[38;5;241m.\u001b[39mlog_evaluation(period\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)]\n\u001b[0;32m    152\u001b[0m     )\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Save best model\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent/Models/lgbm_fold\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_seed\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# Predict validation\u001b[39;00m\n\u001b[0;32m    156\u001b[0m val_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_val)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\numpy_pickle.py:553\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 553\u001b[0m         \u001b[43mNumpyPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    555\u001b[0m     NumpyPickler(filename, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mstart_framing()\n\u001b[1;32m--> 487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(STOP)\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mend_framing()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39mwrite_array(obj, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple returned by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo to six elements\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[38;5;66;03m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state_setter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[38;5;66;03m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[38;5;66;03m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;66;03m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[38;5;66;03m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39mwrite_array(obj, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\pickle.py:972\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    969\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(MARK \u001b[38;5;241m+\u001b[39m DICT)\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 972\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_setitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\pickle.py:998\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tmp:\n\u001b[0;32m    997\u001b[0m         save(k)\n\u001b[1;32m--> 998\u001b[0m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    999\u001b[0m     write(SETITEMS)\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39mwrite_array(obj, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\pickle.py:860\u001b[0m, in \u001b[0;36m_Pickler.save_str\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_large_bytes(BINUNICODE8 \u001b[38;5;241m+\u001b[39m pack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<Q\u001b[39m\u001b[38;5;124m\"\u001b[39m, n), encoded)\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39m_FRAME_SIZE_TARGET:\n\u001b[1;32m--> 860\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_large_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBINUNICODE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<I\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(BINUNICODE \u001b[38;5;241m+\u001b[39m pack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, n) \u001b[38;5;241m+\u001b[39m encoded)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\pickle.py:260\u001b[0m, in \u001b[0;36m_Framer.write_large_bytes\u001b[1;34m(self, header, payload)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Perform direct write of the header and payload of the large binary\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# object. Be careful not to concatenate the header and the payload\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# prior to calling 'write' as we do not want to allocate a large\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# temporary bytes object.\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# We intentionally do not insert a protocol 4 frame opcode to make\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# it possible to optimize file.read calls in the loader.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m write(header)\n\u001b[1;32m--> 260\u001b[0m \u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    input_dir = 'content/data/'\n",
    "    seed = 42\n",
    "    n_folds = 2\n",
    "    target = 'target'\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "# ====================================================\n",
    "# LGBM amex metric\n",
    "# ====================================================\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n",
    "\n",
    "# ====================================================\n",
    "# Train & Evaluate\n",
    "# ====================================================\n",
    "def train_and_evaluate(train, test):\n",
    "    # Label encode categorical features\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\"\n",
    "    ]\n",
    "    cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "    for cat_col in cat_features:\n",
    "        encoder = LabelEncoder()\n",
    "        train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "        test[cat_col] = encoder.transform(test[cat_col])\n",
    "    # Round last float features to 2 decimal place\n",
    "    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "    num_cols = [col for col in num_cols if 'last' in col]\n",
    "    for col in num_cols:\n",
    "        train[col + '_round2'] = train[col].round(2)\n",
    "        test[col + '_round2'] = test[col].round(2)\n",
    "    # Get feature list\n",
    "    features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': \"binary_logloss\",\n",
    "        'boosting': 'dart',\n",
    "        'seed': CFG.seed,\n",
    "        'num_leaves': 100,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.20,\n",
    "        'bagging_freq': 10,\n",
    "        'bagging_fraction': 0.50,\n",
    "        'n_jobs': -1,\n",
    "        'lambda_l2': 2,\n",
    "        'min_data_in_leaf': 40,\n",
    "        'device': 'gpu',                # Enable GPU\n",
    "        'gpu_platform_id': 0,           # Usually 0\n",
    "        'gpu_device_id': 0,             # Usually 0 for single GPU\n",
    "        'max_bin': 63,                  # Recommended for GPU speedup\n",
    "        'gpu_use_dp': False             # Use single precision for consumer GPUs\n",
    "        }\n",
    "\n",
    "    # Create a numpy array to store test predictions\n",
    "    test_predictions = np.zeros(len(test))\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train))\n",
    "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "        print(' ')\n",
    "        print('-'*50)\n",
    "        print(f'Training fold {fold} with {len(features)} features...')\n",
    "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "        model = lgb.train(\n",
    "            params = params,\n",
    "            train_set = lgb_train,\n",
    "            num_boost_round = 10500,\n",
    "            valid_sets = [lgb_train, lgb_valid],\n",
    "            # early_stopping_rounds = 100,\n",
    "            # verbose_eval = 500,\n",
    "            feval = lgb_amex_metric,\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=100),\n",
    "                       lgb.log_evaluation(period=500)]\n",
    "            )\n",
    "        # Save best model\n",
    "        joblib.dump(model, f'content/Models/lgbm_fold{fold}_seed{CFG.seed}.pkl')\n",
    "        # Predict validation\n",
    "        val_pred = model.predict(x_val)\n",
    "        # Add to out of folds array\n",
    "        oof_predictions[val_ind] = val_pred\n",
    "        # Predict the test set\n",
    "        test_pred = model.predict(test[features])\n",
    "        test_predictions += test_pred / CFG.n_folds\n",
    "        # Compute fold metric\n",
    "        score = amex_metric(y_val, val_pred)\n",
    "        print(f'Our fold {fold} CV score is {score}')\n",
    "        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "        gc.collect()\n",
    "    # Compute out of folds metric\n",
    "    score = amex_metric(train[CFG.target], oof_predictions)\n",
    "    print(f'Our out of folds CV score is {score}')\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "    oof_df.to_csv(f'content/OOF/oof_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "    # Create a dataframe to store test prediction\n",
    "    test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "    test_df.to_csv(f'content/Predictions/test_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "    \n",
    "seed_everything(CFG.seed)\n",
    "train, test = read_data()\n",
    "train_and_evaluate(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f748f94",
   "metadata": {},
   "source": [
    "# seed blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4851393a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f9647a6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f22e386a",
   "metadata": {
    "papermill": {
     "duration": 0.003186,
     "end_time": "2022-07-20T12:57:44.391142",
     "exception": false,
     "start_time": "2022-07-20T12:57:44.387956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Read Submission File\n",
    "\n",
    "This is the submission file corresponding to the output of the previous pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9460a28e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T12:57:44.399914Z",
     "iopub.status.busy": "2022-07-20T12:57:44.399099Z",
     "iopub.status.idle": "2022-07-20T12:57:46.292862Z",
     "shell.execute_reply": "2022-07-20T12:57:46.291786Z"
    },
    "papermill": {
     "duration": 1.900838,
     "end_time": "2022-07-20T12:57:46.295544",
     "exception": false,
     "start_time": "2022-07-20T12:57:44.394706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../input/new-data/submission(9).csv')\n",
    "#sub.to_csv('test_lgbm_baseline_5fold_seed42.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e925b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T12:57:46.306698Z",
     "iopub.status.busy": "2022-07-20T12:57:46.305852Z",
     "iopub.status.idle": "2022-07-20T12:57:46.383497Z",
     "shell.execute_reply": "2022-07-20T12:57:46.382246Z"
    },
    "papermill": {
     "duration": 0.086505,
     "end_time": "2022-07-20T12:57:46.385883",
     "exception": false,
     "start_time": "2022-07-20T12:57:46.299378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>924621.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.225231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.362114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.065756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.036171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.471146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.037961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          prediction\n",
       "count  924621.000000\n",
       "mean        0.225231\n",
       "std         0.362114\n",
       "min        -0.065756\n",
       "25%        -0.036171\n",
       "50%         0.001452\n",
       "75%         0.471146\n",
       "max         1.037961"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18fa6d2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T12:57:46.394221Z",
     "iopub.status.busy": "2022-07-20T12:57:46.393827Z",
     "iopub.status.idle": "2022-07-20T12:57:52.153634Z",
     "shell.execute_reply": "2022-07-20T12:57:52.152178Z"
    },
    "papermill": {
     "duration": 5.767566,
     "end_time": "2022-07-20T12:57:52.157040",
     "exception": false,
     "start_time": "2022-07-20T12:57:46.389474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>924621.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.222979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.358493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.065099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.035809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.466434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.027581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          prediction\n",
       "count  924621.000000\n",
       "mean        0.222979\n",
       "std         0.358493\n",
       "min        -0.065099\n",
       "25%        -0.035809\n",
       "50%         0.001438\n",
       "75%         0.466434\n",
       "max         1.027581"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['prediction'] *= .99\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c11cb3",
   "metadata": {
    "papermill": {
     "duration": 0.006541,
     "end_time": "2022-07-20T12:57:52.170881",
     "exception": false,
     "start_time": "2022-07-20T12:57:52.164340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22.519766,
   "end_time": "2022-07-20T12:57:53.405481",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-20T12:57:30.885715",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
